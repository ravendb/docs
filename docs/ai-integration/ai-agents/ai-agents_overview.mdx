---
title: "AI agents: Overview"
hide_table_of_contents: true
sidebar_label: Overview
sidebar_position: 0
---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import LanguageSwitcher from "@site/src/components/LanguageSwitcher";
import LanguageContent from "@site/src/components/LanguageContent";

# AI agents: Overview
<Admonition type="note" title="">

* An **AI Agent** is an ongoing service that resides on a RavenDB server.  
  After its creation by a RavenDB client, an agent can respond to client requests by mediating between the client, an AI model, and a RavenDB database.  
  
* An AI agent can provide the AI model with a set of Query and Action tools.  
  The AI model can then facilitate these tools and query the database or request the client to perform actions.  

* The client gains this way the ability to communicate with an AI model that has access to the database, and to easily automate complex workflows that leverage the AI model's insights and suggestions.  

* In this article:
   * [Common use cases](../../ai-integration/ai-agents/ai-agents_overview#common-use-cases)  
   * [Defining and running AI agents](../../ai-integration/ai-agents/ai-agents_overview#defining-and-running-an-ai-agent)
      * [The main stages in defining an AI agent](../../ai-integration/ai-agents/ai-agents_overview#the-main-stages-in-defining-an-ai-agent)
      * [Initiating a conversation](../../ai-integration/ai-agents/ai-agents_overview#initiating-a-conversation)
   * [AI agent usage flow chart](../../ai-integration/ai-agents/ai-agents_overview#ai-agent-usage-flow-chart)
   * [Stream LLM responses](../../ai-integration/ai-agents/ai-agents_overview#stream-llm-responses)
   * [Initial context queries](../../ai-integration/ai-agents/ai-agents_overview#initial-context-queries)
   * [Security concerns](../../ai-integration/ai-agents/ai-agents_overview#security-concerns)
   * [AI agents and other AI features](../../ai-integration/ai-agents/ai-agents_overview#ai-agents-and-other-ai-features)

</Admonition>

## Common use cases

AI agents are designed to easily integrate AI capabilities into applications and workflows. They can interact with users, intelligently retrieve and process data from public sites and proprietary databases, and apply actions based on roles they are requested to take and the data they have access to. Some of the tasks and applications they can be tailored to perform include:  

* **Customer support chatbot agents** can answer customer queries based on information available to the public as well as internal knowledge bases, provide troubleshooting steps, and guide users through processes in real time.  

* **Data analysis and reporting agents** can analyze large datasets to extract relevant data and present it in a user-friendly format, escalate customer issues and application output, create reports and highlight points of interest, and help businesses make informed decisions.  

* **Automated content generation agents** can generate summaries, add automated comments to articles and and application-generated contents, reference readers to related material, and create marketing content based on user input and stored information.

* **Workflow automation agents** can automate repetitive tasks such as email sorting, spam filtering, form filling, or file organization.  

* **Intelligent recommendation agents** can provide personalized recommendations based on user preferences and available data, e.g. a _library assistant_ suggesting books and other resources, an _HR office assistant_ recommending rewards for employees based on their performance and available facilities near their residence, or an _e-commerce assistant_ recommending products.  

<hr />

## Defining and running an AI agent

An AI agent is defined by a client and runs on a RavenDB server.  
Once defined, the agent can be invoked by the client to handle user requests, respond to events tracked by the client, and so on.  

<Admonition type="note" title="">
* [Learn to create an AI agent using the client API](../../ai-integration/ai-agents/creating-ai-agents/creating-ai-agents_api)  
* [Learn to create an AI agent using Studio](../../ai-integration/ai-agents/creating-ai-agents/creating-ai-agents_studio)  
</Admonition>

### The main stages in defining an AI agent:
* Defining a **connection string** to the AI model  
* Defining the **agent configuration**, including -  
  * Basic agent settings, like the unique ID by which the system recognizes the task.  
  * A system prompt that defines the AI model's role  
  * a JSON schema that defines the layout for the LLM response.  
  * Optional **agent parameters** that RQL queries that you include in your query tools will be able to reference (see below).  
  * Optional **query tools** that allow the LLM to query the database through the agent.  
  * Optional **action tools** that allow the LLM to request the client to perform actions.  

### Initiating a conversation:
To initiate a conversation with the agent the client needs to provide -  
* Values for **agent parameters**  
  If agent parameters are defined for query tools, providing their values when starting a conversation is mandatory.  
  E.g., you can define the RQL query `from "Orders" where ShipTo.Country == $country`, where `$country` is an agent parameter. When you start a conversation with the agent, you must provide a value for `$country` parameter. When the LLM uses this query, it will embed this value instead of the parameter.  
  Providing query values when starting a conversation gives the client the ability to customize the interaction by its needs, as well as limit the scope of LLM queries.  
* A **user prompt** that defines the user's request.  
* **conversation history**  
  If you want to maintain a continuous conversation with the LLM, you need to send it the entire history of the conversation so far. Conversation history is automatically kept in a dedicated `@conversations` collection and can be retrieved from it and continued.  

<hr />

## AI agent usage flow chart

The flow chart below illustrates the interaction between the User, RavenDB client, AI agent, AI model, and RavenDB database.  

![AI agent usage flow chart](./assets/ai-agents_flowchart.png)

1. **User `<->` Client flow**  
   Users can use clients that interact with the AI agent. The user can provide input through the client, and get responses from the agent.

2. **Client `<->` Database flow**  
   The client can interact with the database directly, either by its own initiative or as a result of AI agent action requests.  
   When performing actions on behalf of the AI agent, the client will return the agent the results of these actions.  

3. **Client `<->` Agent flow**  
    * The client can invoke the agent, pass it parameter values for query tools, provide it with a user prompt to initiate a conversation, and send it the history of the conversation so far.  
    * The agent can respond to the client with answers to user prompts, or with requests for the client to perform actions.  
    * E.g., the client can pass the agent a research topic, a user prompt that guides the AI model to act as a research assistant, and the history of the conversation so far.  
      The agent can respond with a summary of the research topic, and a request for the client to save it in the database.  

4. **Agent `<->` Database flow**  
    * The agent can query the database on behalf of the AI model.  
    * A query tool's RQL query may include _agent parameters_, which are placeholders for values provided by the user. When this is the case, the agent will replace these parameters with values provided by the user before running the query.  
    * A query tool's RQL query may also include parameters that are placeholders for values that the AI model is permitted to fill. When this is the case, the agent will replace these parameters with values provided by the AI model before running the query.  
    * When the query ends, the agent will return its results to the AI model.  

5. **Agent `<->` Model flow**  
    * When starting a conversation, the agent provides the AI model with -  
       * A system prompt that defines the model's role and how it is expected to fulfill it  
       * A JSON schema that defines the layout for the model's response  
       * Query and Action tools  
       * If this is a continuation of an ongoing conversation - the history of the conversation so far  
       * A user prompt that initiates this part of the conversation
    * The AI model can respond to the agent with -  
       * Answers to user prompts  
       * Requests for the agent to query the database, optionally with values for query parameters that the AI model is permitted to fill  
       * Requests for the client to perform actions  
    * The agent can respond to the AI model with -  
       * Results of database queries  
       * Results of client actions  

<hr />

## Stream LLM responses

Rather than wait for the LLM to finish generating a response and then pass it in its entirety to the client, the agent can stream response chunks (determined by the LLM, e.g. words or symbols) to the client one by one, immediately as each chunk is returned by the LLM, allowing the client to process and display the response gradually.  

Streaming can ease the processing of lengthy LLM responses for clients, and create a better user experience by keeping users from waiting and providing them with a continuous, fluent interaction.  

Streaming is supported by most AI models, including OpenAI services like GPT-4 and Ollama models.  

[Learn how to stream LLM responses using the API](../../ai-integration/ai-agents/creating-ai-agents/creating-ai-agents_api#stream-llm-responses)  

<hr />

## Initial context queries

The initial context queries are designed to gather relevant information from the database before the main conversation begins. These queries help set the stage for a more informed and context-aware interaction between the user and the AI agent.

1. **User Intent**: The agent should first determine the user's intent by asking clarifying questions or making initial queries to understand the context better.
2. **Relevant Data Retrieval**: Based on the user's intent, the agent can issue queries to retrieve relevant data from the database. This may include user profiles, previous interactions, or specific documents related to the user's query.
3. **Contextual Information**: The agent should also gather any additional contextual information that may be useful for the conversation. This could include metadata about the user's environment, preferences, or constraints.

By performing these initial context queries, the AI agent can create a more tailored and effective interaction with the user.

<hr />

## Security concerns

https://issues.hibernatingrhinos.com/issue/RavenDB-24777/AI-Agent-Security-Concerns

<hr />

## AI agents and other AI features

### AI agents and vector search
