import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

<Admonition type="note" title="">

* This article explains how to run a vector search using a **dynamic query**.  
  To learn how to run a vector search using a static-index, see [vector search using a static-index](../../../ai-integration/vector-search/vector-search-using-static-index.mdx).

* In this article:
  * [What is a vector search](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#what-is-a-vector-search)
  * [Dynamic vector search - query overview](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---query-overview)
    * [Creating embeddings for the auto-index](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#creating-embeddings-for-the-auto-index)
    * [Retrieving results](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#retrieving-results)
    * [The dynamic query parameters](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#the-dynamic-query-parameters)
    * [Corax auto-indexes](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#corax-auto-indexes)
  * [Dynamic vector search - querying TEXT](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-text)
    * [Querying raw text](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#querying-raw-text)
    * [Querying pre-made embeddings generated by tasks](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#querying-pre-made-embeddings-generated-by-tasks)
  * [Dynamic vector search - querying NUMERICAL content](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-numerical-content)
  * [Dynamic vector search - querying for similar documents](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-for-similar-documents)
  * [Dynamic vector search - exact search](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---exact-search)
  * [Quantization options](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options)
  * [Querying vector fields and regular data in the same query](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#querying-vector-fields-and-regular-data-in-the-same-query)
  * [Combining multiple vector searches in the same query](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#combining-multiple-vector-searches-in-the-same-query)
  * [Syntax](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#syntax)
    
</Admonition>

## What is a vector search

* Vector search is a method for finding documents based on their **contextual similarity** to the search item provided in a given query.
 
* Your data is converted into vectors, known as **embeddings**, and stored in a multidimensional space.  
  Unlike traditional keyword-based searches, which rely on exact matches,
  vector search identifies vectors closest to your query vector and retrieves the corresponding documents.

## Dynamic vector search - query overview

<Admonition type="note" title="">

#### Overview

* A dynamic vector search query can be performed on:  
  * Raw text stored in your documents.
  * Pre-made embeddings that you created yourself and stored using these [Data types](../../../ai-integration/vector-search/data-types-for-vector-search.mdx).
  * Pre-made embeddings that are automatically generated from your document content  
    by RavenDB's [Embeddings generation tasks](../../../ai-integration/generating-embeddings/overview.mdx) using external service providers.

* Note: Vector search queries cannot be used with [Subscription queries](../../../client-api/data-subscriptions/creation/api-overview.mdx#subscription-query).

* When executing a dynamic vector search query, RavenDB creates a [Corax Auto-Index](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#corax-auto-indexes) to process the query,  
  and the results are retrieved from that index.    

* To make a **dynamic vector search query**:
    * From the Client API - use the `vector_search` method family
    * In RQL - use the `vector.search()` method
    * Examples are provided below

</Admonition>

<Admonition type="note" title="">

#### Creating embeddings for the Auto-index

* **Creating embeddings from TEXTUAL content**:  

    * **Pre-made embeddings via tasks**:  
      Embeddings can be created from textual content in your documents by defining [Tasks that generate embeddings](../../../ai-integration/generating-embeddings/overview.mdx).  
      When performing a dynamic vector search query over textual data and explicitly specifying the task,
      results will be retrieved by comparing your search term against the embeddings previously generated by that task.  
      A query example is available in: [Querying pre-made embeddings generated by tasks](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#querying-pre-made-embeddings-generated-by-tasks).  
  
    * **Default embeddings generation**:  
      When querying textual data without specifying a task, RavenDB generates an embedding vector for the specified document field in each document of the queried collection,
      using the built-in [bge-micro-v2](https://huggingface.co/TaylorAI/bge-micro-v2) sentence-transformer model.
      A query example is available in: [Querying raw text](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#querying-raw-text).

* **Creating embeddings from NUMERICAL arrays**:  
  When querying over pre-made numerical arrays that are already in vector format,  
  RavenDB will index them without transformation (unless further quantization is applied).  
  A query example is available in: [Vector search on numerical content](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-numerical-content).
    <Admonition type="warning" title="">
    To avoid index errors, ensure that the dimensionality of these numerical arrays (i.e., their length)  
    is consistent across all your source documents for the field you are querying.  
    If you wish to enforce such consistency -  
    perform a vector search using a [Static-index](../../../ai-integration/vector-search/vector-search-using-static-index.mdx) instead of a dynamic query.
    </Admonition> 

* **Quantizing the embeddings**:  
  The embeddings are quantized based on the parameters specified in the query.  
  Learn more about quantization in [Quantization options](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options).

* **Indexing the embeddings**:  
  RavenDB indexes the embeddings on the server using the [HNSW algorithm](https://en.wikipedia.org/wiki/Hierarchical_navigable_small_world).  
  This algorithm organizes embeddings into a high-dimensional graph structure,  
  enabling efficient retrieval of Approximate Nearest Neighbors (ANN) during queries.

</Admonition>

<Admonition type="note" title="">

#### Retrieving results

* **Processing the query**:  
  To ensure consistent comparisons, the **search term** is transformed into an embedding vector using the same method as the document fields.
  The server will search for the most similar vectors in the indexed vector space,
  taking into account all the [query parameters](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#the-dynamic-query-parameters) described below.  
  The documents that correspond to the resulting vectors are then returned to the client. 

* **Search results**:  
  By default, the resulting documents will be ordered by their score.
  You can modify this behavior using the [Indexing.Corax.VectorSearch.OrderByScoreAutomatically](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchorderbyscoreautomatically) configuration key.  
  In addition, you can apply any of the 'order by' methods to your query, as explained in [sort query results](../../../client-api/session/querying/sort-query-results.mdx).

</Admonition>

<Admonition type="note" title="">

#### The dynamic query parameters

* **Source data format**  
  RavenDB supports performing vector search on TEXTUAL values or NUMERICAL arrays.  
  the source data can be formatted as `Text`, `Single`, `Int8`, or `Binary`.

* **Target quantization**  
  You can specify the quantization encoding for the embeddings that will be created from source data.  
  Learn more about quantization in [Quantization options](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options).  

* **Minimum similarity**  
  You can specify the minimum similarity to use when searching for related vectors.  
  The value can be between `0.0` and `1.0`.  
    * A value closer to `1.0` requires higher similarity between vectors,  
      while a value closer to `0.0` allows for less similarity.
    * **Important**: To filter out less relevant results when performing vector search queries,  
      it is recommended to explicitly specify the minimum similarity level at query time.

    If not specified, the default value is taken from the following configuration key:
    [Indexing.Corax.VectorSearch.DefaultMinimumSimilarity](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchdefaultminimumsimilarity).

* **Number of candidates**  
  You can specify the maximum number of vectors that RavenDB will return from a graph search.  
  The number of the resulting documents that correspond to these vectors may be:
    * lower than the number of candidates - when multiple vectors originated from the same document.
    * higher than the number of candidates - when the same vector is shared between multiple documents.

    If not specified, the default value is taken from the following configuration key:
    [Indexing.Corax.VectorSearch.DefaultNumberOfCandidatesForQuerying](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchdefaultnumberofcandidatesforquerying).

* **Search method**
    * _Approximate Nearest-Neighbor search_ (Default):   
      Search for related vectors in an approximate manner, providing faster results.
    * _Exact search_:   
      Perform a thorough scan of the vectors to find the actual closest vectors,  
      offering better accuracy but at a higher computational cost.  
      Learn more in [Exact search](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---exact-search).

</Admonition>

<Admonition type="note" title="">

#### Corax auto-indexes

* Only [Corax indexes](../../../indexes/search-engine/corax.mdx) support vector search.

* Even if your **default auto-index engine** is set to Lucene (via [Indexing.Auto.SearchEngineType](../../../server/configuration/indexing-configuration.mdx#indexingautosearchenginetype)),  
  performing a vector search using a dynamic query will create a new auto-index based on Corax.

* Normally, new dynamic queries extend existing [auto-indexes](../../../client-api/session/querying/how-to-query.mdx#queries-always-provide-results-using-an-index) if they require additional fields.  
  However, a dynamic query with a vector search will not extend an existing Lucene-based auto-index.

    <Admonition type="note" title="">
    For example, suppose you have an existing **Lucene**-based auto-index on the Employees collection: e.g.:  
    `Auto/Employees/ByFirstName`.  

    Now, you run a query that:  

      * searches for Employees by _LastName_ (a regular text search)
      * and performs a vector search over the _Notes_ field.

    The following new **Corax**-based auto-index will be created:  
    `Auto/Employees/ByLastNameAndVector.search(embedding.text(Notes))`,  
    and the existing **Lucene** index on Employees will not be deleted or extended.    
    </Admonition>
 
</Admonition>

## Dynamic vector search - querying TEXT

### Querying raw text

* The following example searches for Product documents where the _'Name'_ field is similar to the search term `"italian food"`.

* Since the query does Not specify an [Embeddings generation task](../../../ai-integration/generating-embeddings/overview.mdx),
  RavenDB dynamically generates embedding vectors for the _'Name'_ field of each document in the queried collection using the built-in
  [bge-micro-v2](https://huggingface.co/TaylorAI/bge-micro-v2) text-embedding model.  
  The generated embeddings are indexed within the auto-index.  
  Unlike embeddings pre-made by tasks, this process does not create dedicated collections for storing embeddings.  

* Since this query does not specify a target quantization format,
  the generated embedding vectors will be encoded in the default _Single_ format (single-precision floating-point).  
  Refer to [Quantization options](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options) for examples that specify the destination quantization.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_products = list(
        session.query(object_type=Product)
        .vector_search_text("Name", "italian food", minimum_similarity=0.82, number_of_candidates=20)
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_products = list(
        session.advanced.raw_query("from 'Products' where vector.search(embedding.text(Name), $searchTerm, 0.82, 20)")
        .add_parameter("searchTerm", "italian food")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
// Query the Products collection
from "Products"
// Call 'vector.search'
// Wrap the document field 'Name' with 'embedding.text' to indicate the source data type
where vector.search(embedding.text(Name), "italian food", 0.82, 20)
```
</TabItem>
</Tabs>

* Executing the above query on the RavenDB sample data will create the following **auto-index**:  
  `Auto/Products/ByVector.search(embedding.text(Name))`

    ![Search for italian food 1](../assets/vector-search-1.png)
  
* Running the same query at a lower similarity level will return more results related to _"Italian food"_ but they may be less similar:

    ![Search for italian food 2](../assets/vector-search-2.png)

### Querying pre-made embeddings generated by tasks

* The following example searches for Category documents where the _'Name'_ field is similar to the search term `"candy"`.

* The query explicitly specifies the **identifier** of the embeddings generation task that was defined in
  [this example](../../../ai-integration/generating-embeddings/embeddings-generation-task.mdx#configuring-an-embeddings-generation-task---from-the-studio).  
  An `InvalidQueryException` will be thrown if no embeddings generation task with the specified identifier exists.  
  
  To avoid this error, you can verify that the specified embeddings generation task exists before issuing the query.  
  Refer to [Get embeddings generation task details](../../../ai-integration/generating-embeddings/overview.mdx#get-embeddings-generation-task-details) to learn how to programmatically check which tasks are defined and what their identifiers are.

* Results are retrieved by comparing the search term against the pre-made embeddings generated by the specified task,  
  which are stored in the [Embedding collections](../../../ai-integration/generating-embeddings/embedding-collections.mdx).
  To ensure consistent comparisons, the search term is transformed into an embedding using the same embeddings generation task.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_categories = list(
        session.query(object_type=Category).vector_search_text_using_task(
            "Name", "candy", "id-for-task-open-ai", minimum_similarity=0.75
        )
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_categories = list(
        session.advanced.raw_query(
            "from 'Categories' where vector.search(embedding.text(Name, ai.task('id-for-task-open-ai')), $searchTerm, 0.75)"
        )
        .add_parameter("searchTerm", "candy")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
// Query the Categories collection
from "Categories"
// Call 'vector.search'
// Specify the identifier of the task that generated the embeddings inside the 'ai.task' method
where vector.search(embedding.text(Name, ai.task('id-for-task-open-ai')), $searchTerm, 0.75)
{"searchTerm": "candy"}
```
</TabItem>
</Tabs>

* Executing the above query on the RavenDB sample data will create the following **auto-index**:  
  `Auto/Categories/ByVector.search(embedding.text(Name|ai.task('id-for-task-open-ai')))`

## Dynamic vector search - querying NUMERICAL content

* The following examples will use the sample data shown below.  
  The _Movie_ class includes various formats of numerical vector data.  
  Note: This sample data is minimal to keep the examples simple.

* Note the usage of RavenDB's dedicated data type, [RavenVector](../../../ai-integration/vector-search/data-types-for-vector-search.mdx#ravenvector), which is highly optimized for reading and writing arrays to disk.
  Learn more about the source data types suitable for vector search in [Data types for vector search](../../../ai-integration/vector-search/data-types-for-vector-search.mdx).

* Unlike vector searches on text, where RavenDB transforms the raw text into an embedding vector,  
  numerical vector searches require your source data to already be in an embedding vector format.  

* If your raw data is in a _float_ format, you can request further quantization of the embeddings that will be indexed in the auto-index.
  See an example of this in: [Quantization options](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options).  

* Raw data that is already formatted as _Int8_ or _Binary_ **cannot** be quantized to lower-form (e.g. Int8 -&gt; Int1).  
  When storing data in these formats in your documents, you should use [RavenDB’s `VectorQuantizer` methods](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#vectorquantizer).

#### Sample data:

<Tabs groupId='languageSyntax'>
<TabItem value="Class" label="Class">
```python
class Movie:
    def __init__(
        self,
        Id: str = None,
        title: str = None,
        tags_embedded_as_single: list[float] = None,
        tags_embedded_as_int8: list[list[int]] = None,
        tags_embedded_as_base_64: list[str] = None,
        movie_photo_embedding: list[float] = None,
    ):
        self.Id = Id
        self.title = title

        # This field will hold numerical vector data - Not quantized
        self.tags_embedded_as_single = tags_embedded_as_single

        # This field will hold numerical vector data - Quantized to Int8
        self.tags_embedded_as_int8 = tags_embedded_as_int8

        # This field will hold numerical vector data - Encoded in Base64 format
        self.tags_embedded_as_base_64 = tags_embedded_as_base_64

        # A field for holding a numerical vector data produced by a multimodal model
        # that converts an image into an embedding
        self.movie_photo_embedding = movie_photo_embedding
```
</TabItem>
<TabItem value="Sample_data" label="Sample_data">
```python
movie1 = Movie(
    title="Hidden Figures",
    Id="movies/1",
    # Embedded vector represented as float values
    tags_embedded_as_single=[6.599999904632568, 7.699999809265137],

    # Embedded vectors encoded in Base64 format
    tags_embedded_as_base_64=["zczMPc3MTD6amZk+", "mpmZPs3MzD4AAAA/"],

    # Array of embedded vectors quantized to Int8
    # Use VectorQuantizer.to_int8() to convert float arrays to lists of signed integers
    tags_embedded_as_int8=[VectorQuantizer.to_int8([0.1, 0.2]), VectorQuantizer.to_int8([0.3, 0.4])],

    # Example of an image embedding
    # In a real scenario, this vector would come from a multimodal model
    # such as CLIP, OpenCLIP, or similar
    movie_photo_embedding=[0.123, -0.045, 0.987, 0.564, -0.321, 0.220],
)

movie2 = Movie(
    title="The Shawshank Redemption",
    Id="movies/2",
    tags_embedded_as_single=[8.800000190734863, 9.899999618530273],
    tags_embedded_as_base_64=["zcxMPs3MTD9mZmY/", "zcxMPpqZmT4zMzM/"],
    tags_embedded_as_int8=[VectorQuantizer.to_int8([0.5, 0.6]), VectorQuantizer.to_int8([0.7, 0.8])],
    movie_photo_embedding=[0.456, -0.056, 0.123, 0.899, -0.765, 0.881],
)

session.store(movie1, "movies/1")
session.store(movie2, "movies/2")
session.save_changes()
```
</TabItem>
<TabItem value="Sample_document" label="Sample_document">
```python
{
    "title": "Hidden Figures",
    "tags_embedded_as_single": [
        6.599999904632568,
        7.699999809265137
    ],
    "tags_embedded_as_int8": [
        [
            63,
            127,
            -51,
            -52,
            76,
            62
        ],
        [
            95,
            127,
            -51,
            -52,
            -52,
            62
        ]
    ],
    "tags_embedded_as_base_64": [
        "zczMPc3MTD6amZk+",
        "mpmZPs3MzD4AAAA/"
    ],
    "movie_photo_embedding": [
        0.123,
        -0.045,
        0.987,
        0.564,
        -0.321,
        0.22
    ],
    "@metadata": {
        "@collection": "Movies",
        "Raven-Python-Type": "__main__.Movie"
    }
}
```
</TabItem>
</Tabs>

#### Examples:

These examples search for Movie documents with vectors similar to the one provided in the query.

<Admonition type="note" title="">

Search on the `tags_embedded_as_single` field,  
which contains numerical data in **floating-point format**. 

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_movies = list(
        session.query(object_type=Movie)
        .vector_search(
            embedding_field="tags_embedded_as_single",
            vector=[6.599999904632568, 7.699999809265137],
            minimum_similarity=0.85,
            number_of_candidates=10,
        )
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_movies = list(
        session.advanced.raw_query(
            "from 'Movies' where vector.search(tags_embedded_as_single, $queryVector, 0.85, 10)", Movie
        )
        .add_parameter("queryVector", [6.599999904632568, 7.699999809265137])
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Movies"
// The source document field type is interpreted as 'Single' by default
where vector.search(tags_embedded_as_single, $queryVector, 0.85, 10)
{ "queryVector" : { "@vector" : [6.599999904632568, 7.699999809265137] }}
```
</TabItem>
</Tabs>

</Admonition>
<Admonition type="note" title="">

Search on the `tags_embedded_as_int8` field,  
which contains numerical data that is already quantized in **_Int8_ format**.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_movies = list(
        session.query(object_type=Movie)
        .vector_search_i8("tags_embedded_as_int8", VectorQuantizer.to_int8([0.1, 0.2]))
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Movies"
// Wrap the source document field name with 'embedding.i8' to indicate the source data type
where vector.search(embedding.i8(tags_embedded_as_int8), $queryVector)
{ "queryVector" : [64, 127, -51, -52, 76, 62] }
```
</TabItem>
</Tabs>

</Admonition>
<Admonition type="note" title="">

Search on the `tags_embedded_as_base_64` field,  
which contains numerical data represented in **_Base64_ format**.

<Tabs groupId='languageSyntax'>
<TabItem value="raw_query" label="raw_query">
```python
similar_movies = list(
        session.advanced.raw_query("from 'Movies' where vector.search(tags_embedded_as_base_64, $queryVectorBase64)", Movie)
        .add_parameter("queryVectorBase64", "zczMPc3MTD6amZk+")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Movies"
// * Wrap the source document field name using 'embedding.<format>' to specify
//   the source data type from which the Base64 string was generated.
// * If the document field is Not wrapped, 'single' is assumed as the default source type. 
where vector.search(tags_embedded_as_base_64, $queryVectorBase64)
{ "queryVectorBase64" : "zczMPc3MTD6amZk+" }
```
</TabItem>
</Tabs>

</Admonition>

## Dynamic vector search - querying for similar documents

* In the above examples, to find documents with similar content, the query was given an arbitrary input -  
  either a [raw textual search term](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-text) 
  or a [numerical query vector](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#dynamic-vector-search---querying-numerical-content).

* RavenDB also allows you to search for documents whose content is similar to an **existing document**:  

   * To do so, use the RQL `forDoc` method and specify the existing document ID. See the example below.

   * When performing a dynamic vector query over a field, index-entries are generated in the auto-index, 
     one per document in the collection. Each index-entry contains the document ID and the embedding vector for the queried field.  

   * RavenDB retrieves the embedding that was indexed for the queried field in the specified document and uses it as the query vector for the similarity comparison.

   * The results will include documents whose indexed embeddings are most similar to the one stored in the referenced document’s index-entry.

```sql
from "Products"
// Pass a document ID to the 'forDoc' method to find similar documents
where vector.search(embedding.text(Name), embedding.forDoc($documentID), 0.82)
{"documentID" : "Products/7-A"}
```

Running the above example on RavenDB’s sample data returns the following documents that have similar content in their _Name_ field:
(Note: the results include the referenced document itself, _Products/7-A_)

```text
ID: products/7-A  ... Name: "Uncle Bob's Organic Dried Pears"
ID: products/51-A ... Name: "Manjimup Dried Apples"
ID: products/6-A  ... Name: "Grandma's Boysenberry Spread"
```

The auto-index generated by running the above dynamic query is:  
`Auto/Products/ByVector.search(embedding.text(Name))`

You can **view the index-entries** of this auto-index in Studio's query view:

![Query the auto index](../assets/view-auto-index-entries-1.png)

1. Go to the Query view in Studio
2. Query the index
3. Open the settings dialog:

![Open the settings dialog](../assets/view-auto-index-entries-2.png)

![The index entries](../assets/view-auto-index-entries-3.png)

## Dynamic vector search - exact search

* When performing a dynamic vector search query, you can specify whether to perform an **exact search** to find the closest similar vectors in the vector space:
  * A thorough scan will be performed to find the actual closest vectors.
  * This ensures better accuracy but comes at a higher computational cost.

* If exact is Not specified, the search defaults to the **Approximate Nearest-Neighbor** (ANN) method,  
  which finds related vectors in an approximate manner, offering faster results.

* The following example demonstrates how to specify the exact method in the query.  
  Setting the param is similar for both text and numerical content searches.
  <Tabs groupId='languageSyntax'>
  <TabItem value="query" label="query">
  ```python
  similar_products = list(
          session.query(object_type=Product)
          .vector_search_text("Name", "italian food", is_exact=True)
          .wait_for_non_stale_results()
      )
  ```
  </TabItem>
  <TabItem value="raw_query" label="raw_query">
  ```python
  similar_products = list(
          session.advanced.raw_query("from 'Products' where exact(vector.search(embedding.text(Name), $searchTerm))")
          .add_parameter("searchTerm", "italian food")
          .wait_for_non_stale_results()
      )
  ```
  </TabItem>
  <TabItem value="RQL" label="RQL">
  ```sql
  from "Products"
  // Wrap the vector.search query with the 'exact()' method
  where exact(vector.search(embedding.text(Name), "italian food"))
  ```
  </TabItem>
  </Tabs>

## Quantization options

#### What is quantization:

Quantization is a technique that reduces the precision of numerical data.
It converts high-precision values, such as 32-bit floating-point numbers, into lower-precision formats like 8-bit integers or binary representations.

The quantization process, applied to each dimension (or item) in the numerical array, 
serves as a form of compression by reducing the number of bits used to represent each value in the vector.
For example, transitioning from 32-bit floats to 8-bit integers significantly reduces data size while preserving the vector's essential structure.  

Although it introduces some precision loss, quantization minimizes storage requirements and optimizes memory usage.
It also reduces computational overhead, making operations like similarity searches faster and more efficient.

#### Quantization in RavenDB:

For non-quantized raw 32-bit data or text stored in your documents,
RavenDB allows you to choose the quantization format for the generated embeddings stored in the index.
The quantization format applies to how vectors are stored internally in the index, regardless of the client language used to submit the data.

The selected quantization type determines the similarity search technique that will be applied.  
If no target quantization format is specified, the `Single` option will be used as the default.

The available quantization options are:  

   * `Single` (a 32-bit floating point value per dimension):  
     Provides precise vector representations.  
     The [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) method will be used for searching and matching.  

   * `Int8` (an 8-bit integer value per dimension):  
     Reduces storage requirements while maintaining good performance.  
     Saves up to 75% storage compared to 32-bit floating-point values.  
     The Cosine similarity method will be used for searching and matching.  

   * `Binary` (1-bit per dimension):  
     Minimizes storage usage, suitable for use cases where binary representation suffices.  
     Saves approximately 96% storage compared to 32-bit floating-point values.  
     The [Hamming distance](https://en.wikipedia.org/wiki/Hamming_distance) method will be used for searching and matching.  
      
     <Admonition type="note" title="">
     If your documents contain data that is already quantized,  
     it cannot be re-quantized to a lower precision format (e.g., Int8 cannot be converted to Binary).
     </Admonition>

#### Examples

<Admonition type="note" title="">

* In this example: 
  * The source data consists of text.
  * The generated embeddings will use the _Int8_ format.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_products = list(
        session.query(object_type=Product)
        .vector_search_text_i8("Name", "italian food")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_products = list(
        session.advanced.raw_query("from 'Products' where vector.search(embedding.text_i8(Name), $searchTerm)")
        .add_parameter("searchTerm", "italian food")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Products"
// Wrap the 'Name' field with 'embedding.text_i8'
where vector.search(embedding.text_i8(Name), $searchTerm)
{ "searchTerm" : "italian food" }
```
</TabItem>
</Tabs>

</Admonition>
<Admonition type="note" title="">

* In this example:  
    * The source data is an array of 32-bit floats.
    * The generated embeddings will use the _Binary_ format.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_movies = list(
        session.query(object_type=Movie)
        .vector_search_f32_i1("tags_embedded_as_single", [6.599999904632568, 7.699999809265137])
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_movies = list(
        session.advanced.raw_query("from 'Movies' where vector.search(embedding.f32_i1(tags_embedded_as_single), $queryVector)")
        .add_parameter("queryVector", [6.599999904632568, 7.699999809265137])
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Movies"
// Wrap the 'tags_embedded_as_single' field with 'embedding.f32_i1'
where vector.search(embedding.f32_i1(tags_embedded_as_single), $queryVector)
{ "queryVector" : { "@vector" : [6.599999904632568,7.699999809265137] }}
```
</TabItem>
</Tabs>

</Admonition>

#### Field configuration methods in RQL:  

The following methods are available for performing a vector search via RQL:

<Admonition type="note" title="">

* `embedding.text`:  
  Generates embeddings from text as multi-dimensional vectors with 32-bit floating-point values,  
  without applying quantization.  

* `embedding.text_i8`:  
  Generates embeddings from text as multi-dimensional vectors with 8-bit integer values.

* `embedding.text_i1`:   
  Generates embeddings from text as multi-dimensional vectors in a binary format.  
* `embedding.f32_i8`:  
  Converts multi-dimensional vectors with 32-bit floating-point values into vectors with 8-bit integer values.  

* `embedding.f32_i1`:  
  Converts multi-dimensional vectors with 32-bit floating-point values into vectors in a binary format.  
* `embedding.i8`:  
  Indicates that the source data is already quantized as Int8  (cannot be further quantized).  

* `embedding.i1`:  
  Indicates that the source data is already quantized as binary (cannot be further quantized).  

</Admonition>

Wrap the field name using any of the relevant methods listed above, based on your requirements.  
For example, the following RQL encodes **text to Int8**:
```sql
from "Products"
// Wrap the document field with 'embedding.text_i8'
where vector.search(embedding.text_i8(Name), "italian food", 0.82, 20)
```

When the field name is Not wrapped in any method,
the underlying values are treated as numerical values in the form of **32-bit floating-point** (Single) precision.
For example, the following RQL will use the floating-point values as they are, without applying further quantization:
```sql
from "Movies"
// No wrapping
where vector.search(tags_embedded_as_single, $queryVector, 0.85, 10)
{"queryVector" : { "@vector" : [6.599999904632568, 7.699999809265137] }}
```

## Querying vector fields and regular data in the same query

* You can perform a vector search and a regular search in the same query.  
  A single auto-index will be created for both search predicates.

* In the following example, results will include Product documents with content similar to "italian food" in their _Name_ field and a _PricePerUnit_ above 20.
  The following auto-index will be generated:  
  `Auto/Products/ByPricePerUnitAndVector.search(embedding.text(Name))`.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
similar_products = list(
        session.query(object_type=Product)
        .vector_search_text("Name", "italian food", 0.75, 16)
        .where_greater_than("PricePerUnit", 35)
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
similar_products = list(
        session.advanced.raw_query(
            "from 'Products' where (PricePerUnit > $minPrice) and (vector.search(embedding.text(Name), $searchTerm, 0.75, 16))"
        )
        .add_parameter("minPrice", 35)
        .add_parameter("searchTerm", "italian food")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Products"
// The filtering condition:
where (PricePerUnit > $minPrice)
and (vector.search(embedding.text(Name), $searchTerm, 0.75, 16))
{ "minPrice" : 35.0, "searchTerm" : "italian food" }
```
</TabItem>
</Tabs>

<Admonition type="info" title="">

**Impact of _NumberOfCandidates_ on query results**:  

* When combining a vector search with a filtering condition, the filter applies only to the documents retrieved within the `NumberOfCandidates` param limit.
  Increasing or decreasing _NumberOfCandidates_ can affect the query results.
  A larger _NumberOfCandidates_ increases the pool of documents considered,
  improving the chances of finding results that match both the vector search and the filter condition.

* For example, in the above query, the vector search executes with: Similarity `0.75` and NumberOfCandidates `16`.
  Running this query on RavenDB's sample data returns **2** documents. 

* However, if you increase _NumberOfCandidates_, the query will retrieve more candidate documents before applying the filtering condition.
  If you run the following query:
  ```sql
  from "Products"
  where (PricePerUnit > $minPrice)
  // Run vector search with similarity 0.75 and NumberOfCandidates 25
  and (vector.search(embedding.text(Name), $searchTerm, 0.75, 25))
  { "minPrice" : 35.0, "searchTerm" : "italian food" }
  ```
  now the query returns **4** documents instead of **2**.

</Admonition>

## Combining multiple vector searches in the same query

* You can combine multiple vector search statements in the same query using logical operators.  
  This is useful when you want to retrieve documents that match more than one vector-based criterion.
 
* This can be done using [raw_query](../../../client-api/session/querying/how-to-query.mdx#sessionadvancedrawquery) or raw [RQL](../../../client-api/session/querying/what-is-rql.mdx).

* In the example below, the results will include companies that match one of two vector search conditions:  
  * Companies from European countries with a _Name_ similar to "snack"
  * Or companies with a _Name_ similar to "dairy"

* Running the query example on the RavenDB sample data will generate the following auto-index:  
  `Auto/Companies/ByVector.search(embedding.text(Address.Country))AndVector.search(embedding.text(Name))`.  
  This index includes two vector fields: _Address.Country_ and _Name_.

<Tabs groupId='languageSyntax'>
<TabItem value="query" label="query">
```python
companies = list(
        session.query(object_type=Company)
        # Use open_subclause & close_subclause to differentiate between clauses:
        # ======================================================================
        .open_subclause()
        # Search for companies that sell snacks or similar
        .vector_search_text("Name", "snack", 0.78)
        # Use 'and_also' for an AND operation
        .and_also()
        # Search for companies located in Europe
        .vector_search_text("Address.Country", "europe", 0.82)
        .close_subclause()
        # Use 'or_else' for an OR operation
        .or_else()
        .open_subclause()
        # Search for companies that sell dairy products or similar
        .vector_search_text("Name", "dairy", 0.80)
        .close_subclause()
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="raw_query" label="raw_query">
```python
companies = list(
        session.advanced.raw_query(
            """
            from Companies
            where
                (
                    vector.search(embedding.text(Name), $searchTerm1, 0.78)
                    and
                    vector.search(embedding.text(Address.Country), $searchTerm2, 0.82)
                )
                or
                (
                    vector.search(embedding.text(Name), $searchTerm3, 0.80)
                )
            """,
            Company,
        )
        .add_parameter("searchTerm1", "snack")
        .add_parameter("searchTerm2", "europe")
        .add_parameter("searchTerm3", "dairy")
        .wait_for_non_stale_results()
    )
```
</TabItem>
<TabItem value="RQL" label="RQL">
```sql
from "Companies"
where
(
  vector.search(embedding.text(Name), $searchTerm1, 0.78)
  and
  vector.search(embedding.text(Address.Country), $searchTerm2, 0.82)
)
or
(
  vector.search(embedding.text(Name), $searchTerm3, 0.80)
)
{"searchTerm1" : "snack", "searchTerm2" : "europe", "searchTerm3" : "dairy"}
```
</TabItem>
</Tabs>

<Admonition type="info" title="">

**How multiple vector search clauses are evaluated**:

* Each vector search clause is evaluated independently - the search algorithm runs separately for each vector field.

* Each clause retrieves a limited number of candidates, determined by the _NumberOfCandidates_ parameter.
  * You can explicitly set this value in the query clause, see [query parameters](../../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#the-dynamic-query-parameters).  
  * If not specified, it is taken from the [Indexing.Corax.VectorSearch.DefaultNumberOfCandidatesForQuerying](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchdefaultnumberofcandidatesforquerying) configuration key (default is 16).
 
* **The final result set** is computed by applying the logical operators (and, or) between these independently retrieved sets.

* To improve the chances of getting intersecting results, consider increasing the _NumberOfCandidates_ in each vector search clause.
  This expands the pool of documents considered by each clause, raising the likelihood of finding matches that satisfy the combined logic.

</Admonition>

## Syntax

`vector_search` methods:  

<TabItem>
```python
def vector_search(
        self,
        embedding_field: str,
        vector: Union[List[float], str],
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_i8(
        self,
        embedding_field: str,
        vector: List[int],
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_i1(
        self,
        embedding_field: str,
        vector: List[int],
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text(
        self,
        embedding_field: str,
        vector: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text_using_task(
        self,
        embedding_field: str,
        vector: str,
        task_name: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_f32_i8(
        self,
        embedding_field: str,
        vector: List[float],
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_f32_i1(
        self,
        embedding_field: str,
        vector: List[float],
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text_i8(
        self,
        embedding_field: str,
        vector: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text_i1(
        self,
        embedding_field: str,
        vector: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text_i8_using_task(
        self,
        embedding_field: str,
        vector: str,
        task_name: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...


def vector_search_text_i1_using_task(
        self,
        embedding_field: str,
        vector: str,
        task_name: str,
        minimum_similarity: float = None,
        number_of_candidates: int = None,
        is_exact: bool = VectorSearch.DEFAULT_IS_EXACT,
) -> DocumentQuery[_T]:
    ...
```
</TabItem>

| Parameter | Type | Description |
|-----------|------|-------------|
| **embedding_field** | `str` | Name of the document field whose content or embeddings are used for the vector search (e.g. `"Name"`, `"tags_embedded_as_single"`). |
| **vector** | <ul><li><code>str</code></li><li><code>List[float]</code></li><li><code>List[int]</code></li></ul> | Query value (for text methods - the search string, for numeric methods - the embedding/vector value passed to the search). |
| **task_name** | `str` | Identifier of the embeddings generation task to use when querying pre-generated embeddings. |
| **minimum_similarity** | `float` | Minimum similarity between the queried value and the indexed value for the vector search to match. |
| **number_of_candidates** | `int` | Number of candidate nodes for the HNSW algorithm.<br/>Higher values improve accuracy but require more computation. |
| **is_exact** | `bool` | `False` - vector search will be performed in an approximate manner.<br/>`True` - vector search will be performed in an exact manner. |

The default value for `minimum_similarity` is defined by this configuration key:  
[Indexing.Corax.VectorSearch.DefaultMinimumSimilarity ](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchdefaultminimumsimilarity).

The default value for `number_of_candidates` is defined by this configuration key:  
[Indexing.Corax.VectorSearch.DefaultNumberOfCandidatesForQuerying](../../../server/configuration/indexing-configuration.mdx#indexingcoraxvectorsearchdefaultnumberofcandidatesforquerying).

`VectorEmbeddingType`:
<TabItem>
```python
class VectorEmbeddingType(Enum):
    SINGLE = "Single" 
    INT8 = "Int8"  
    BINARY = "Binary" 
    TEXT = "Text" 
```
</TabItem>

#### `VectorQuantizer`:   

RavenDB provides the following quantizer methods.  
Use them to transform your raw data to the desired format.  
Other quantizers may not be compatible.  

<TabItem>
```python
class VectorQuantizer:
    @staticmethod
    def to_int8(raw_embedding: List[float]) -> List[int]:
        ...

    @staticmethod
    def to_int1(raw_embedding: List[float]) -> List[int]:
        ...
```
</TabItem>
