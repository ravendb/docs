---
title: "Vector Search - Overview"
sidebar_label: "Overview"
sidebar_position: 1
hide_table_of_contents: true
---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import LanguageSwitcher from "@site/src/components/LanguageSwitcher";
import LanguageContent from "@site/src/components/LanguageContent";
import ContentFrame from '@site/src/components/ContentFrame';
import Panel from '@site/src/components/Panel';

<Admonition type="note" title="">

* In this article:
    * [What is a vector database](../../ai-integration/vector-search/vector-search-overview.mdx#what-is-a-vector-database)
    * [Vector search in RavenDB](../../ai-integration/vector-search/vector-search-overview.mdx#vector-search-in-ravendb)
      * [Vector search using a dynamic query](../../ai-integration/vector-search/vector-search-overview.mdx#vector-search-using-a-dynamic-query)
      * [Vector search using a static-index](../../ai-integration/vector-search/vector-search-overview.mdx#vector-search-using-a-static-index)
    * [Why choose RavenDB as your vector database](../../ai-integration/vector-search/vector-search-overview.mdx#why-choose-ravendb-as-your-vector-database)
    
</Admonition>

<Panel heading="What is a vector database">

* A vector database stores data as high-dimensional numerical representations (embedding vectors),  
  enabling searches based on contextual meaning and vector similarity rather than exact keyword matches.  
  Instead of relying on traditional indexing, it retrieves relevant results by measuring how close vectors are in a multi-dimensional space.

* Vector databases are widely used in applications such as:  

   * Semantic search – Finding documents based on meaning rather than exact words.
   * Recommendation engines – Suggesting products, media, or content based on similarity.
   * AI and machine learning – Powering LLMs, multi-modal search, and object detection.

**Embeddings**:  

* A vector database stores data as high-dimensional vectors in a high-dimensional space.  
  These vectors, known as **embeddings**, are mathematical representations of your data.

* Each embedding is an array of numbers (e.g. [0.45, 3.6, 1.25, 0.7, ...]), where each dimension represents specific characteristics of the data, capturing its contextual meaning.  
  Words, phrases, entire documents, images, audio, and other types of data can all be vectorized.

* The raw data is converted into embeddings using [transformers](https://huggingface.co/docs/transformers).  
  To optimize storage and computation, transformers can encode embeddings with lower-precision data types, such as 8-bit integers, through a technique called [quantization](../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options).

**Indexing embeddings and searching**:  

* The embedding vectors are indexed and stored in a vector space.
  Their positions reflect relationships and characteristics of the data as determined by the model that generated them.
  The distance between two embeddings in the vector space correlates with the similarity of their original inputs within that model's context.
  
* Vectors representing similar data are positioned close to each other in the vector space.  
  This is achieved using algorithms such as [HNSW](https://en.wikipedia.org/wiki/Hierarchical_navigable_small_world), which is designed for indexing and querying embeddings.
  HNSW constructs a graph-based structure that efficiently retrieves approximate nearest neighbors in high-dimensional spaces.

* This architecture enables **similarity searches**. Instead of conventional keyword-based queries,  
  a vector database lets you find relevant data based on semantic and contextual meaning.

</Panel>

<Panel heading="Vector search in RavenDB">
    
Vector search in RavenDB can be performed in two main ways:  
* By running a **dynamic query** directly on a collection.  
* By querying a **static index** that contains vector fields.  

---
    
<Admonition type="note" title="">
    
## Vector search using a dynamic query
    
You can perform ad-hoc vector search queries without creating an index in advance.  
RavenDB will automatically generate a Corax auto-index behind the scenes to support the query.  
    
**When using a dynamic vector query, you can**:  
* Query raw text  
* Query pre-generated embeddings (created by RavenDB)  
* Query pre-generated embeddings (created externally)  
   
---
    
* ✔ **Query raw text**:    
   Provide a plain text phrase as your search term.  
   RavenDB will generate embeddings on the fly for:
   * the textual content of your documents, and
   * the search term itself
   using the built-in `bge-micro-v2` model.  
    
   These embeddings are then compared to find semantically similar documents.  
   Learn more in: [Dynamic vector search - querying TEXT](../../ai-integration/vector-search/vector-search-using-dynamic-query#dynamic-vector-search---querying-text).

* ✔ **Query pre-generated embeddings (created by RavenDB)**:  
   If your database already contains embeddings generated by a RavenDB [Embeddings generation task](../../ai-integration/generating-embeddings/overview),  
   you can query them by:
   * Specifying the task ID used to generate the stored embeddings.
   * Providing a text search term, which will be embedded using the same model for comparison.
   
   Learn more in: [Querying pre-made embeddings generated by tasks](../../ai-integration/vector-search/vector-search-using-dynamic-query#querying-pre-made-embeddings-generated-by-tasks).
    
* ✔ **Query pre-generated embeddings (created externally)**:   
   If your documents contain embeddings that were Not generated by RavenDB’s _embeddings generation tasks_,  
   but instead created externally (e.g., via OpenAI or a custom model you run), RavenDB can use those vectors directly during search.
    
   This option is especially useful for non-textual content, such as **images, audio, or video**, which RavenDB cannot embed automatically. 
   You store the vectors in your documents as numeric arrays (e.g., _float[]_) and provide an embedding vector as the search input.  
    
   Learn more in: [Dynamic vector search - querying NUMERICAL content](../../ai-integration/vector-search/vector-search-using-dynamic-query#dynamic-vector-search---querying-numerical-content).

<Admonition type="info" title="">    
The full description of how to perform a **dynamic vector search query** is available in article:  
[Vector Search using a Dynamic Query](../../ai-integration/vector-search/vector-search-using-dynamic-query). 
It explains how to configure inputs and search parameters, apply quantization,
combine vector and regular filters, choose between exact or approximate modes, and more.    
</Admonition>

</Admonition>
    
<Admonition type="note" title="">
    
## Vector search using a static-index

Static indexes are optimized for performance and repeated use.
You can define a static-index (Corax only) that includes one or more vector fields, giving you full control over how embeddings are created, stored, and queried.
    
**When defining the static index, you can index the following types of content in vector fields**:  
* Index embeddings from raw text
* Index embeddings from pre-generated TEXT embeddings (via RavenDB)
* Index embeddings from pre-made NUMERICAL embeddings (e.g. images)
* Index embeddings from attachment content
    
---
    
* ✔ **Index embeddings from raw text**:  
   * <u>At indexing time</u>:  
     RavenDB generates embeddings from the raw text in your documents using the built-in `bge-micro-v2` model, and stores them in the index’s vector field.  
   * <u>When querying the index</u>:  
     You provide a text search term, which is embedded using the same model and compared against the indexed vectors.
     
       Learn more in: [Indexing vector data - TEXT](../../ai-integration/vector-search/vector-search-using-static-index#indexing-vector-data---text).
    
* ✔ **Index embeddings from pre-generated TEXT embeddings (via RavenDB)**:  
   * <u>At indexing time</u>:  
     If your documents contain embeddings generated by a RavenDB [Embeddings generation task](../../ai-integration/generating-embeddings/overview),  
     you can index them directly by specifying the task ID used to generate them in the index definition.    
   * <u>When querying the index</u>:    
     You provide a text search term, which is embedded using the same task (i.e., same model), and compared against the stored vectors.
   
       Learn more in: [Indexing pre-made text-embeddings](../../ai-integration/vector-search/vector-search-using-static-index#indexing-pre-made-text-embeddings).
    
* ✔ **Index embeddings from pre-made NUMERICAL embeddings (e.g. images)**:  
    * <u>At indexing time</u>:  
      If you have numerical embeddings generated outside RavenDB (e.g., from text, images, videos, etc.), you can store them in your documents either:  
      * as numeric arrays in properties (e.g., float[], byte[]), or  
      * as binary attachments  
    
      These values can then be indexed directly into a vector field.
    
    * <u>When querying the index</u>, you can search using:  
      * A text input, which is embedded before comparison, or  
      * A numeric vector, provided directly as the search term  
        
      Learn more in: [Indexing vector data - NUMERICAL](../../ai-integration/vector-search/vector-search-using-static-index#indexing-vector-data---numerical).

* ✔ **Index embeddings from attachment content**:    
   You can index attachments using a static-index to enable vector search on their content.  
   Learn more in: [Indexing attachments for vector search](../../ai-integration/vector-search/indexing-attachments-for-vector-search).    
 
<Admonition type="info" title="">    
The full description of how to perform a **vector search query using a static-index** in RavenDB is available in article:
[Vector Search using a Static-Index](../../ai-integration/vector-search/vector-search-using-static-index).
It explains how to define the index, configure indexing & query-time parameters, query for similar documents, and more.    
</Admonition>
    
</Admonition>
    
</Panel>

<Panel heading="Why choose RavenDB as your vector database">

✅ **An integrated solution**:  

* RavenDB provides an integrated solution that combines high-performance NoSQL capabilities with advanced vector indexing and querying features,
  enabling efficient storage and management of high-dimensional vector data.

✅ **Reduced infrastructure complexity**:

* RavenDB's built-in vector search eliminates the need for external vector databases,  
  simplifying your infrastructure and reducing maintenance overhead.

✅ **AI integration**:  

* You can use RavenDB as the **vector database** for your AI-powered applications, including large language models (LLMs).
  This eliminates the need to transfer data to expensive external services for vector similarity search,
  providing a cost-effective and efficient solution for vector-based operations.

✅ **Multiple field types in indexes**:  

* An index can consist of multiple index-fields, each having a distinct type, such as a standard field, a spatial field, a full-text search field, or a **vector field**.
  This flexibility allows you to work with complex documents containing various data types and retrieve meaningful insights by querying the index across all these fields.  
  An example is available in [Indexing multiple field types](../../ai-integration/vector-search/vector-search-using-static-index.mdx#indexing-multiple-field-types).

* Document [attachments](../../ai-integration/vector-search/indexing-attachments-for-vector-search.mdx) can also be indexed as vector fields, and Map-Reduce indexes can incorporate vector fields in their reduce phase, 
  further extending the versatility of your data processing and search capabilities.

✅ **Built-in embedding support**:

* **Textual input**:  
  Embeddings can be automatically generated from textual content within your documents by defining  
  [Embeddings generation tasks](../../ai-integration/generating-embeddings/overview.mdx).
  These tasks connect to external embedding providers such as **Azure OpenAI, OpenAI, Hugging Face, Google AI, Ollama, or Mistral AI**.
  If no task is specified, embeddings will be generated using the built-in [bge-micro-v2](https://huggingface.co/TaylorAI/bge-micro-v2) model.
  
     When querying with a phrase, RavenDB generates an embedding for the search term using the same model applied to the document data
     and compares it against the indexed embeddings.

* **Numerical arrays input**:  
  Documents in RavenDB can also contain numerical arrays with **pre-made embeddings** created elsewhere.  
  Use RavenDB's dedicated data type, [RavenVector](../../ai-integration/vector-search/data-types-for-vector-search.mdx#ravenvector), to store these embeddings in your document entities.  
  This type is highly optimized to reduce storage space and enhance the speed of reading arrays from disk.

* **HNSW algorithm usage**:  
  All embeddings, whether generated from textual input or pre-made numerical arrays,  
  are indexed and searched for using the [HNSW](https://en.wikipedia.org/wiki/Hierarchical_navigable_small_world) algorithm.

* **Optimize storage via quantization**:  
  RavenDB allows you to select the quantization format for the generated embeddings when creating the index.  
  Learn more in [Quantization options](../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx#quantization-options).

* **Perform vector search**:  
  Leverage RavenDB's [Auto-indexes](../../ai-integration/vector-search/vector-search-using-dynamic-query.mdx)
  and [Static indexes](../../ai-integration/vector-search/vector-search-using-static-index.mdx) to perform a vector search,  
  retrieving documents based on contextual similarity rather than exact word matches.

</Panel>
