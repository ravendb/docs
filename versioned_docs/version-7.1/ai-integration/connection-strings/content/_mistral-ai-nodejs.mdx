import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import ContentFrame from '@site/src/components/ContentFrame';
import Panel from '@site/src/components/Panel';

<Admonition type="note" title="">

* This article explains how to define a connection string to [Mistral AI](https://docs.mistral.ai/capabilities/embeddings/),  
  enabling RavenDB to seamlessly integrate its [Embeddings generation tasks](../../../ai-integration/generating-embeddings/overview.mdx) with Mistral's API.

* Note: RavenDB currently supports only text embeddings with Mistral AI.  
  Chat models are not supported through this integration.    
    
* In this article:
  * [Define the connection string - from Studio](../../../ai-integration/connection-strings/mistral-ai.mdx#define-the-connection-string-from-studio)
  * [Define the connection string - from the Client API](../../../ai-integration/connection-strings/mistral-ai.mdx#define-the-connection-string-from-the-client-api)
  * [Syntax](../../../ai-integration/connection-strings/mistral-ai.mdx#syntax) 
    
</Admonition>

<Panel heading="Define the connection string - from Studio">

![connection string to mistral ai](../assets/mistral-ai.png)

1. **Name**  
   Enter a name for this connection string.

2. **Identifier** (optional)  
   Learn more about the identifier in the [connection string identifier](../../../ai-integration/connection-strings/overview.mdx#the-connection-string-identifier) section.

3. **Model Type**  
   Select "Text Embeddings".

4. **Connector**  
   Select **Mistral AI** from the dropdown menu.

5. **API key**  
   Enter the API key used to authenticate requests to Mistral AI's API.

6. **Endpoint**  
   Select or enter the Mistral AI endpoint for generating embeddings from text.

7. **Model**  
   Select or enter the Mistral AI text embedding model to use.

8. **Max concurrent query batches**: (optional)
   * When making vector search queries, the content of the search terms must also be converted to embeddings to compare them against the stored vectors.  
     Requests to generate such query embeddings via the AI provider are sent in batches.
   * This parameter defines the maximum number of these batches that can be processed concurrently.  
     You can set a default value using the [Ai.Embeddings.MaxConcurrentBatches](../../../server/configuration/ai-integration-configuration.mdx#aiembeddingsmaxconcurrentbatches) configuration key.

9. Click **Test Connection** to confirm the connection string is set up correctly.

10. Click **Save** to store the connection string or **Cancel** to discard changes.

</Panel>

<Panel heading="Define the connection string - from the Client API">

<TabItem value="create_connection_string_mistral_ai" label="create_connection_string_mistral_ai">
```js
// Define the connection string to Mistral AI
const connectionString = new AiConnectionString();

// Connection string name & identifier    
connectionString.name = "ConnectionStringToMistralAI";
connectionString.identifier = "identifier-to-the-connection-string"; // optional

// Model type
connectionString.modelType = "TextEmbeddings";

// Mistral AI connection settings
connectionString.mistralAiSettings = new MistralAiSettings(
    "mistral-embed", // Name of text embedding model to use
    "your-api-key",
    "https://api.mistral.ai/v1");

// Optionally, override the default maximum number of query embedding batches
// that can be processed concurrently
connectionString.mistralAiSettings.embeddingsMaxConcurrentBatches = 10;

// Deploy the connection string to the server    
const putConnectionStringOp = new PutConnectionStringOperation(connectionString);
const putConnectionStringResult = await store.maintenance.send(putConnectionStringOp);
```
</TabItem>

</Panel>

<Panel heading="Syntax">

<TabItem value="mistral_ai_settings" label="mistral_ai_settings">
```js
class AiConnectionString
{
    name;              // string
    identifier;        // string (optional)
    modelType;         // "TextEmbeddings" | "Chat"
    mistralAiSettings; // MistralAiSettings
} 

class MistralAiSettings
{
    model;          // string
    endpoint;       // string
    apiKey;         // string
    
    // Maximum number of query embedding batches that can be processed concurrently.
    embeddingsMaxConcurrentBatches; // number
}
```
</TabItem>
    
</Panel>