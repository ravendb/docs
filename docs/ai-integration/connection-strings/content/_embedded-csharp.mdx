import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

<Admonition type="note" title="">

* This article explains how to define a connection string to the [bge-micro-v2](https://huggingface.co/TaylorAI/bge-micro-v2) model.  
  This model, designed exclusively for embeddings generation, is embedded within RavenDB, enabling RavenDB to seamlessly handle its
  [Embeddings generation tasks](../../../ai-integration/generating-embeddings/overview.mdx) without requiring an external AI service.  

* Running the model locally consumes processor resources and will impact RavenDB's overall performance,  
  depending on your workload and usage patterns.

* In this article:
  * [Define the connection string - from the Studio](../../../ai-integration/connection-strings/embedded.mdx#define-the-connection-string---from-the-studio)
  * [Define the connection string - from the Client API](../../../ai-integration/connection-strings/embedded.mdx#define-the-connection-string---from-the-client-api)
  * [Syntax](../../../ai-integration/connection-strings/embedded.mdx#syntax)

</Admonition>

## Define the connection string - from the Studio

![connection string to the embedded model](../assets/embedded.png)

1. **Name**  
   Enter a name for this connection string.

2. **Identifier** (optional)  
   Learn more about the identifier in the [connection string identifier](../../../ai-integration/connection-strings/overview.mdx#the-connection-string-identifier) section.

3. **Model Type**  
   Select "Text Embeddings".

4. **Connector**  
   Select **Embedded (bge-micro-v2)** from the dropdown menu.

5. **Max concurrent query batches**: (optional)
   * When making vector search queries, the content of the search terms must also be converted to embeddings to compare them against the stored vectors.  
     Requests to generate such query embeddings via the AI provider are sent in batches.
   * This parameter defines the maximum number of these batches that can be processed concurrently.  
     You can set a default value using the [Ai.Embeddings.MaxConcurrentBatches](../../../server/configuration/ai-integration-configuration.mdx#aiembeddingsmaxconcurrentbatches) configuration key.

6. Click **Save** to store the connection string or **Cancel** to discard changes.

## Define the connection string - from the Client API

<TabItem value="create_connection_string_embedded" label="create_connection_string_embedded">
```csharp
using (var store = new DocumentStore())
{
    // Define the connection string to the embedded model
    var connectionString = new AiConnectionString
    {
        // Connection string name & identifier
        Name = "ConnectionStringToEmbedded", 
        Identifier = "identifier-to-the-connection-string", // optional
        
        // Model type
        ModelType = AiModelType.TextEmbeddings,
    
        // Embedded model settings
        // No user configuration is required for the embedded model,
        // as it uses predefined values managed internally by RavenDB.
        EmbeddedSettings = new EmbeddedSettings()
    };
    
    // Optionally, override the default maximum number of query embedding batches
    // that can be processed concurrently 
    connectionString.EmbeddedSettings.EmbeddingsMaxConcurrentBatches = 10;
    
    // Deploy the connection string to the server
    var operation = new PutConnectionStringOperation<AiConnectionString>(connectionString);
    var putConnectionStringResult = store.Maintenance.Send(operation);
}
```
</TabItem>

## Syntax

<TabItem value="embedded_settings" label="embedded_settings">
```csharp
public class AiConnectionString
{
    public string Name { get; set; }
    public string Identifier { get; set; }
    public AiModelType ModelType { get; set; }
    public EmbeddedSettings EmbeddedSettings { get; set; }
}

public class EmbeddedSettings : AbstractAiSettings
{
}

public class AbstractAiSettings
{
    public int? EmbeddingsMaxConcurrentBatches { get; set; }
}
```
</TabItem>
